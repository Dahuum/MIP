{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240955eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LSTM Neural Network for Predictive Maintenance using PyTorch\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d23ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b2f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(os.cpu_count())\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba48e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üß† PyTorch LSTM DEEP LEARNING MODEL\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"   PyTorch: {torch.__version__} | Threads: {torch.get_num_threads()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"SEQUENCE_LENGTH\": 30,\n",
    "    \"PREDICTION_HOURS\": 24,\n",
    "    \"HIDDEN_SIZE\": 64,\n",
    "    \"NUM_LAYERS\": 2,\n",
    "    \"DROPOUT\": 0.2,\n",
    "    \"EPOCHS\": 30,\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"LEARNING_RATE\": 0.001,\n",
    "    \"SKIP_ROWS\": 15609,\n",
    "    \"SAMPLE_RATE\": 5,\n",
    "    \"DUST_WARNING\": 15.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2975ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚öôÔ∏è  CONFIG:\", CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä STEP 1: Loading data...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c38a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "failures_df = pd.read_csv(\"failure_events_with_dust.csv\")\n",
    "failures_df[\"timestamp\"] = pd.to_datetime(failures_df[\"timestamp\"])\n",
    "print(f\"   ‚úì {len(failures_df)} failures loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1058cb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataframemin.csv\", skiprows=range(1, CONFIG[\"SKIP_ROWS\"] + 1))\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d/%m/%Y %H:%M\")\n",
    "df.columns = [\"Date\", \"Motor_Current\", \"Temp_Opposite\", \"Temp_Motor\", \n",
    "              \"Vib_Opposite\", \"Vib_Motor\", \"Valve_Opening\"]\n",
    "df = df.sort_values(\"Date\").reset_index(drop=True)\n",
    "df = df.iloc[::CONFIG[\"SAMPLE_RATE\"]].reset_index(drop=True)\n",
    "print(f\"   ‚úì {len(df):,} records (sampled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5286ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_cols = [\"Motor_Current\", \"Temp_Opposite\", \"Temp_Motor\", \n",
    "               \"Vib_Opposite\", \"Vib_Motor\", \"Valve_Opening\"]\n",
    "for col in sensor_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "df[sensor_cols] = df[sensor_cols].ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404250a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Features\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üîß STEP 2: Creating features...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8f49f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = sensor_cols.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d59200",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sensor_cols:\n",
    "    df[f\"{col}_diff\"] = df[col].diff().fillna(0)\n",
    "    feature_cols.append(f\"{col}_diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583c16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Vib_Total\"] = df[\"Vib_Motor\"] + df[\"Vib_Opposite\"]\n",
    "df[\"Temp_Diff\"] = df[\"Temp_Motor\"] - df[\"Temp_Opposite\"]\n",
    "feature_cols.extend([\"Vib_Total\", \"Temp_Diff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017d15e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"   ‚úì {len(feature_cols)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c0452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Labels\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üè∑Ô∏è  STEP 3: Creating labels...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6001a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = 0\n",
    "for _, f in failures_df.iterrows():\n",
    "    start = f[\"timestamp\"] - timedelta(hours=CONFIG[\"PREDICTION_HOURS\"])\n",
    "    mask = (df[\"Date\"] >= start) & (df[\"Date\"] < f[\"timestamp\"])\n",
    "    df.loc[mask, \"label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4516b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = (df[\"label\"] == 1).sum()\n",
    "neg = (df[\"label\"] == 0).sum()\n",
    "print(f\"   ‚úì Positive: {pos:,}, Negative: {neg:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37fd9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Sequences\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üîÑ STEP 4: Preparing sequences...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ffd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df[feature_cols] = scaler.fit_transform(df[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c917174e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "split = int(len(df) * 0.7)\n",
    "train_df = df[:split]\n",
    "test_df = df[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6774f936",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def make_sequences(data, seq_len):\n",
    "    X, y = [], []\n",
    "    vals = data[feature_cols].values\n",
    "    labs = data[\"label\"].values\n",
    "    for i in range(seq_len, len(data)):\n",
    "        X.append(vals[i-seq_len:i])\n",
    "        y.append(labs[i])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f8c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = CONFIG[\"SEQUENCE_LENGTH\"]\n",
    "X_train, y_train = make_sequences(train_df, seq_len)\n",
    "X_test, y_test = make_sequences(test_df, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16556f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"   ‚úì Train: {X_train.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6929f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = torch.FloatTensor(X_train)\n",
    "y_train_t = torch.FloatTensor(y_train)\n",
    "X_test_t = torch.FloatTensor(X_test)\n",
    "y_test_t = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f87bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"BATCH_SIZE\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_weight = neg / pos if pos > 0 else 1.0\n",
    "pos_weight = torch.tensor([min(raw_weight, 10.0)])\n",
    "print(f\"   ‚úì Positive class weight: {pos_weight.item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a61ba0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define LSTM Model\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üß† STEP 5: Building LSTM Neural Network...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15f9836",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        last_out = lstm_out[:, -1, :]\n",
    "        out = self.dropout(last_out)\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09896e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(\n",
    "    input_size=len(feature_cols),\n",
    "    hidden_size=CONFIG[\"HIDDEN_SIZE\"],\n",
    "    num_layers=CONFIG[\"NUM_LAYERS\"],\n",
    "    dropout=CONFIG[\"DROPOUT\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c06431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"   ‚úì Model parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a68726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéì STEP 6: Training LSTM...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a87e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG[\"LEARNING_RATE\"])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91cfc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n   Epoch  |  Loss   | Train Acc | Train Rec |  Progress\")\n",
    "print(\"   \" + \"-\" * 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5321ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(CONFIG[\"EPOCHS\"]):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    true_pos = 0\n",
    "    actual_pos = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs > 0.5).float()\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "        total += len(y_batch)\n",
    "        true_pos += ((preds == 1) & (y_batch == 1)).sum().item()\n",
    "        actual_pos += (y_batch == 1).sum().item()\n",
    "    \n",
    "    acc = correct / total\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_recall = true_pos / actual_pos if actual_pos > 0 else 0\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    bar = \"‚ñà\" * (epoch + 1) + \"‚ñë\" * (CONFIG[\"EPOCHS\"] - epoch - 1)\n",
    "    print(f\"   {epoch+1:3d}    | {avg_loss:.4f} |  {acc:.2%}   |  {train_recall:.2%}   | {bar[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n   ‚úì Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f0d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä STEP 7: Evaluating model...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540909e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test_t)\n",
    "    y_pred_proba = torch.sigmoid(logits).numpy()\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26904e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n   üéØ METRICS:\")\n",
    "print(f\"      Recall:    {recall:.2%}\")\n",
    "print(f\"      Precision: {precision:.2%}\")\n",
    "print(f\"      F1-Score:  {f1:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Failure-Based Evaluation\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ STEP 8: Checking each failure...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a92ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start = df.iloc[split][\"Date\"]\n",
    "test_failures = failures_df[failures_df[\"timestamp\"] >= test_start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82fb166",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n   Testing {len(test_failures)} failures:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e312ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "caught = 0\n",
    "dust_caught = 0\n",
    "total_dust = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf277396",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, failure in test_failures.iterrows():\n",
    "    f_time = failure[\"timestamp\"]\n",
    "    f_type = failure[\"failure_type\"]\n",
    "    dust = failure[\"Dust_Quantity_kg\"]\n",
    "    is_dust = dust >= CONFIG[\"DUST_WARNING\"]\n",
    "    \n",
    "    if is_dust:\n",
    "        total_dust += 1\n",
    "    \n",
    "    window_start = f_time - timedelta(hours=CONFIG[\"PREDICTION_HOURS\"])\n",
    "    test_dates = test_df.iloc[seq_len:][\"Date\"].values\n",
    "    mask = (test_dates >= np.datetime64(window_start)) & (test_dates <= np.datetime64(f_time))\n",
    "    \n",
    "    if mask.sum() > 0:\n",
    "        preds = y_pred[mask]\n",
    "        probs = y_pred_proba[mask]\n",
    "        detected = preds.sum() > 0\n",
    "        max_prob = probs.max()\n",
    "        \n",
    "        if detected:\n",
    "            caught += 1\n",
    "            if is_dust:\n",
    "                dust_caught += 1\n",
    "            status = \"‚úì CAUGHT\"\n",
    "        else:\n",
    "            status = \"‚úó MISSED\"\n",
    "        \n",
    "        dust_icon = \"üå´Ô∏è\" if is_dust else \"  \"\n",
    "        print(f\"   {dust_icon} {status} {f_time} ({f_type}) prob={max_prob:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69583ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_recall = caught / len(test_failures) if len(test_failures) > 0 else 0\n",
    "dust_recall = dust_caught / total_dust if total_dust > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c960b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n   üìä RESULTS:\")\n",
    "print(f\"      Failures: {caught}/{len(test_failures)} caught ({failure_recall:.0%})\")\n",
    "print(f\"      Dust failures: {dust_caught}/{total_dust} ({dust_recall:.0%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d404668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üíæ STEP 9: Saving model...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090eae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"lstm_pytorch_model.pt\")\n",
    "print(\"   ‚úì lstm_pytorch_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a095a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, \"lstm_scaler.pkl\")\n",
    "joblib.dump(feature_cols, \"lstm_features.pkl\")\n",
    "joblib.dump(CONFIG, \"lstm_config.pkl\")\n",
    "print(\"   ‚úì Saved scaler, features, config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e07531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèÜ TRAINING COMPLETE!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fd8008",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "üìä RESULTS:\n",
    "   Failure Recall: {failure_recall:.0%} ({caught}/{len(test_failures)})\n",
    "   Dust Detection: {dust_recall:.0%} ({dust_caught}/{total_dust})\n",
    "   Estimated Savings: ${caught * 200000:,}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904db337",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚è∞ Done:\", datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
